{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "procam-calibration_201118.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rim-yu/procam-calibration/blob/master/procam_calibration_201118.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70qKsQCgiIHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9f53e5-74e5-4201-f012-fb3ed97c9d00"
      },
      "source": [
        "# You need to mount your google drive  to the /content/gdrive folder of your virtual computer\n",
        "# located in the colab server\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "#drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "635aMJnsiLQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b41cb9-5cbd-4342-eba1-188ffe15a710"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "%xmode Verbose\n",
        "%pdb on"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception reporting mode: Verbose\n",
            "Automatic pdb calling has been turned ON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sueX8qH_iMcD"
      },
      "source": [
        "import os\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "#cf: https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/\n",
        "import glob\n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "from matplotlib import pyplot as plt \n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oziZ11CniOHY"
      },
      "source": [
        "def main(proj_height, proj_width, chess_rows, chess_cols, chess_block_size,\n",
        "    graycode_step, black_thr, white_thr,  cameraParamFile):\n",
        "\n",
        "    proj_shape = (proj_height, proj_width)\n",
        "    chess_shape = (chess_rows, chess_cols)\n",
        "    chess_block_size = chess_block_size\n",
        "    gc_step = graycode_step\n",
        "    black_thr = black_thr\n",
        "    white_thr = white_thr \n",
        "    camera_param_file = cameraParamFile \n",
        "\n",
        "    dirnames = sorted(glob.glob('./capture_*'))\n",
        "    if len(dirnames) == 0: \n",
        "        print('Directories \\'./capture_*\\' were not found')\n",
        "        return\n",
        "\n",
        "    print('Searching input files ...')\n",
        "    used_dirnames = [] \n",
        "    gc_fname_lists = [] \n",
        "    for dname in dirnames:\n",
        "        #gc_fnames = sorted(glob.glob(dname + '/graycode_*'))\n",
        "        gc_fnames = sorted(glob.glob(dname + '/graycode*'))\n",
        "        if len(gc_fnames) == 0:  \n",
        "            continue\n",
        "        used_dirnames.append(dname) \n",
        "        gc_fname_lists.append(gc_fnames) \n",
        "        print(' \\'' + dname + '\\' was found')\n",
        "\n",
        "    camP = None \n",
        "    cam_dist = None \n",
        "    path, ext = os.path.splitext(camera_param_file) \n",
        "    if(ext == \".json\"): \n",
        "        camP, cam_dist = loadCameraParam(camera_param_file) \n",
        "        print('load camera parameters')\n",
        "        print(camP)\n",
        "        print(cam_dist)\n",
        "\n",
        "    calibrate(used_dirnames, gc_fname_lists,\n",
        "              proj_shape, chess_shape, chess_block_size, gc_step, black_thr, white_thr,\n",
        "               camP, cam_dist) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stpgd8rmiWM6"
      },
      "source": [
        "def printNumpyWithIndent(tar, indentchar):\n",
        "    print(indentchar + str(tar).replace('\\n', '\\n' + indentchar))  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59yTKzzTiYKQ"
      },
      "source": [
        "def loadCameraParam(json_file):\n",
        "    with open(json_file, 'r') as f:\n",
        "        param_data = json.load(f)\n",
        "        P = param_data['camera']['P']\n",
        "        d = param_data['camera']['distortion']\n",
        "        return np.array(P).reshape([3,3]), np.array(d) # ok "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybb9u2NciZah"
      },
      "source": [
        "def calibrate(dirnames, gc_fname_lists, proj_shape, chess_shape, chess_block_size, gc_step, black_thr, white_thr, camP, camD):\n",
        "\n",
        "    objps = np.zeros((chess_shape[0]*chess_shape[1], 3), np.float32) \n",
        "    # 각 objps 마다 (각 코너 포인트마다) x, y, z 좌표를 저장한다. 저장 장소를 만드는데 모든 값을 0으로 초기화. 10 by 7 array 를 만들고 각 array 값은 좌표임.  \n",
        "    # 첫 번째 인덱스는 모두 사용, 두 번째 인덱스는 2까지만 사용.\n",
        "    objps[:, :2] = chess_block_size * \\\n",
        "        np.mgrid[0:chess_shape[0], 0:chess_shape[1]].T.reshape(-1, 2)\n",
        "\n",
        "    print('Calibrating ...') \n",
        "    gc_height = int((proj_shape[0]-1)/gc_step)+1 \n",
        "    gc_width = int((proj_shape[1]-1)/gc_step)+1 \n",
        "    # 스트라이프의 가로/세로 갯수 정함. \n",
        "\n",
        "    graycode = cv2.structured_light_GrayCodePattern.create(\n",
        "        gc_width, gc_height) \n",
        "    graycode.setBlackThreshold(black_thr)  \n",
        "    graycode.setWhiteThreshold(white_thr) \n",
        "\n",
        "\n",
        "    cam_shape = cv2.imread(gc_fname_lists[0][0], cv2.IMREAD_GRAYSCALE).shape # 카메라 이미지 shape. \n",
        "    # cam_shape = (1600, 2400) \n",
        "    patch_size_half = int(np.ceil(cam_shape[1] / 180)) # ! 왜 180 으로 나누는지 알아보기. !\n",
        "    # 2400/180 = 13.33 ... \n",
        "    print('  patch size :', patch_size_half * 2 + 1) #\n",
        "\n",
        "    cam_corners_list = [] \n",
        "    cam_objps_list = [] \n",
        "    cam_corners_list2 = [] \n",
        "\n",
        "    proj_corners_list = [] \n",
        "    proj_objps_list = [] \n",
        "    \n",
        "    for dname, gc_filenames in zip(dirnames, gc_fname_lists):\n",
        "        print('  checking \\'' + dname + '\\'') \n",
        "        if len(gc_filenames) != graycode.getNumberOfPatternImages() + 2: \n",
        "          # graycode.getNumberOfPatternImages() = 48\n",
        "          # gcfiles include black and white imgs \n",
        "            print('Error : invalid number of images in \\'' + dname + '\\'')\n",
        "            return None \n",
        "\n",
        "        graycode_imgs = [] # imgs -> graycode_imgs\n",
        "        subpixel_imgpoints = [] # _imgpoints -> subpixel_imgpoints\n",
        "\n",
        "        for fname in gc_filenames: \n",
        "            img = cv2.imread(fname)    \n",
        "            _gray = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if cam_shape != _gray.shape: \n",
        "                print('Error : image size of \\'' + fname + '\\' is mismatch')\n",
        "                return None \n",
        "            graycode_imgs.append(_gray)\n",
        "        # end of for loop.\n",
        "\n",
        "        # 맨 뒤 두 장이 black, white img 임\n",
        "        black_img = graycode_imgs.pop() \n",
        "        white_img = graycode_imgs.pop() \n",
        "        # white_img is the image where chessboard corners are clearly seen. \n",
        "\n",
        "        res, cam_img_corners = cv2.findChessboardCorners(white_img, chess_shape) # cam_corners -> cam_img_corners\n",
        "        if not res: \n",
        "            print('Error : chessboard was not found in \\'' +\n",
        "                  gc_filenames[-2] + '\\'')  \n",
        "            return None\n",
        "\n",
        "        _ret, _corners = cv2.findChessboardCorners(white_img, chess_shape, None)\n",
        "\n",
        "        # draw the found corners\n",
        "        if _ret == True: # True 면 코너점들을 찾은 것임. 함수가 성공했단 뜻.\n",
        "\n",
        "           cv2.drawChessboardCorners(white_img, chess_shape,  _corners, _ret);\n",
        "           # I need the first corner at top-left\n",
        "           # if( centers.front().y > centers.back().y){\n",
        "           #  std::cout << \"Reverse order\\n\";\n",
        "           #  std::reverse(centers.begin(),centers.end());\n",
        "           # }\n",
        "\n",
        "           font = cv2.FONT_HERSHEY_PLAIN\n",
        "           fontScale = 3\n",
        "           color = (0,255,0)\n",
        "           thickness = 2 #px\n",
        "\n",
        "           for r in range(0, chess_shape[1]):\n",
        "               for c in range(0, chess_shape[0]):\n",
        "                coord = '(' + str(r) + ',' + str(c) + ')'  \n",
        "                origin = _corners[r* chess_shape[0] + c]\n",
        "                cv2.putText(white_img, coord, origin, font, fontScale, color, thickness, cv2.LINE_AA)\n",
        "               #end of for\n",
        "           #end of for\n",
        "           # Displaying the image\n",
        "           window_name =\"Window For CornerPoints (NonSubPixel)\"\n",
        "           cv2.imshow(window_name, white_img)\n",
        "\n",
        "           _ret, subPixelCorners = cv2.cornerSubPix(white_img, _corners, (5, 5), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
        "                      # draw the found corners\n",
        "           if _ret == True: # True 면 코너점들을 찾은 것임. 함수가 성공했단 뜻.\n",
        "              cv2.drawChessboardCorners(white_img, chess_shape,  subPixelCorners, _ret);\n",
        "              # I need the first corner at top-left\n",
        "              # if( centers.front().y > centers.back().y){\n",
        "              #  std::cout << \"Reverse order\\n\";\n",
        "              #  std::reverse(centers.begin(),centers.end());\n",
        "              # }\n",
        "\n",
        "              font = cv2.FONT_HERSHEY_PLAIN\n",
        "              fontScale = 3\n",
        "              color = (0,255,0)\n",
        "              thickness = 2 #px\n",
        "\n",
        "              for r in range(0, chess_shape[1]):\n",
        "                  for c in range(0, chess_shape[0]):\n",
        "                    coord = '(' + str(r) + ',' + str(c) + ')'  \n",
        "                    origin = subPixelCorners[r* chess_shape[0] + c]\n",
        "                    cv2.putText(white_img, coord, origin, font, fontScale, color, thickness, cv2.LINE_AA)\n",
        "                  #end of for\n",
        "              #end of for\n",
        "              # Displaying the image\n",
        "              window_name =\"Window For CornerPoints (SubPixel)\"\n",
        "              cv2.imshow(window_name, white_img)              \n",
        "        else :\n",
        "            print('Error : chessboard corners were not found in \\'' + gc_filenames[-2] + '\\'') # 0 이면 첫 번째 -1 이면 맨 끝에 -2 맨 끝에서 두 번째. white img 임. \n",
        "            return None\n",
        "\n",
        "        cam_objps_list.append(objps) \n",
        "        # cam_corners_list.append(cam_img_corners) # cam_img_corners 는 subpixel point 가 아님. \n",
        "        cam_corners_list.append(subPixelCorners) # _corners 는 sub pixel image point 임. pixel 보다 더 정확한 것임. \n",
        "\n",
        "        proj_objps = []\n",
        "        proj_corners = []\n",
        "        cam_corners = []\n",
        "\n",
        "        for (corner, objp) in zip(cam_img_corners, objps): # 코너점에 대응되는 objp 을 구하려함. \n",
        "        # cam_img_corners is an array of array of point.\n",
        "        # corner is an array of point.\n",
        "        # corner[0] is point. \n",
        "        # corner[0][0]는 그 포인트의 x 좌표. corner[0][1]는 그 포인트의 y 좌표. \n",
        "        # corner[1] does not exist. corner is actually a point but it is bracketed. \n",
        "            c_x = int(round(corner[0][0])) # 코너의 x 좌표.\n",
        "            c_y = int(round(corner[0][1])) # 코너의 y 좌표. \n",
        "            src_points = []\n",
        "            dst_points = []\n",
        "            # dx, dy 는 원 블럭 내에 포인트. 그 블럭은 c_x, c_y 를 left-top 코너로 하는 블럭. \n",
        "            # patch 라는 건 블럭을 몇 개의 구간으로 나눌 것이냐. 한 블럭의 length 가 96[mm] 임. 13.33 ... 적당히 구간 나누기. \n",
        "            # 구간을 많이 나누면 더 좋을 것 같다. \n",
        "            for dx in range(-patch_size_half, patch_size_half + 1): # patch_size_half = 13.33 ... \n",
        "                for dy in range(-patch_size_half, patch_size_half + 1):\n",
        "                    x = c_x + dx \n",
        "                    y = c_y + dy\n",
        "\n",
        "                    if int(white_img[y, x]) - int(black_img[y, x]) <= black_thr: \n",
        "                        continue\n",
        "\n",
        "                    err, proj_pix = graycode.getProjPixel(graycode_imgs, x, y) \n",
        "                    # x, y 가 image plane 상의 픽셀 좌표. 카메라 이미지 픽셀 좌표에 대응되는 프로젝터 화면 상의 좌표를 구하는 것임.\n",
        "                    # 그간 구한 graycode image 를 다씀. \n",
        "\n",
        "                    if not err:\n",
        "                        src_points.append((x, y))   \n",
        "                        dst_points.append(gc_step*np.array(proj_pix))\n",
        "                    #else:\n",
        "                    #  print(\"decoding of projector points failed.\")\n",
        "                    #  return None\n",
        "\n",
        "            if len(src_points) < patch_size_half**2: \n",
        "                print(\n",
        "                    '    Warning : corner', c_x, c_y,\n",
        "                    'was skiped because decoded pixels were too few (check your images and threasholds)')\n",
        "                continue # go to the for loop again.\n",
        "                # 특정 코너점을 찾으려다가 에러가 남. 카메라 이미지 상의 점과 대응되는 점을 찾을 수가 없다.\n",
        "\n",
        "\n",
        "            h_mat, inliers = cv2.findHomography(\n",
        "                np.array(src_points), np.array(dst_points))\n",
        "            point = h_mat@np.array([corner[0][0], corner[0][1], 1]).transpose()\n",
        "            point_pix = point[0:2]/point[2]\n",
        "            proj_objps.append(objp)\n",
        "            proj_corners.append([point_pix])\n",
        "            cam_corners.append(corner)\n",
        "        # end of for loop : for (corner, objp) in zip(cam_img_corners, objps)\n",
        "\n",
        "        if len(proj_corners) < 3:\n",
        "            print('Error : too few corners were found in \\'' +\n",
        "                  dname + '\\' (less than 3)')\n",
        "            return None\n",
        "\n",
        "        proj_objps_list.append(np.float32(proj_objps)) # 한 체스보드 방향에 대해서 proj_objps 생성됨. \n",
        "        # 리스트의 리스트. 모든 체스보드 방향에 대해서 체스보드 상의 코너점에 대응되는 프로젝터 데이터를 다 모으는 것임.\n",
        "        # 그것을 cv2.calibrateCamera 함수에 넘긴다.\n",
        "        proj_corners_list.append(np.float32(proj_corners))\n",
        "        cam_corners_list2.append(np.float32(cam_corners))\n",
        "    # end of for loop : for dname, gc_filenames in zip(dirnames, gc_fname_lists)\n",
        "    print('Initial solution of camera\\'s intrinsic parameters')\n",
        "    cam_rvecs = []\n",
        "    cam_tvecs = []\n",
        "\n",
        "    if(camP is None): # calibrate camera by using camera corner point list and camera object point list. \n",
        "        ret, cam_int, cam_dist, cam_rvecs, cam_tvecs = cv2.calibrateCamera(\n",
        "            cam_objps_list, cam_corners_list, _gray.shape[::-1], None, None, None, None) \n",
        "        print('  RMS :', ret)\n",
        "\n",
        "    else:\n",
        "        for objp, corners in zip(cam_objps_list, cam_corners_list):\n",
        "            ret, cam_rvec, cam_tvec = cv2.solvePnP(objp, corners, camP, camD) \n",
        "            cam_rvecs.append(cam_rvec)\n",
        "            cam_tvecs.append(cam_tvec)\n",
        "            print('  RMS :', ret)\n",
        "\n",
        "        cam_int = camP\n",
        "        cam_dist = camD\n",
        "\n",
        "    print('  Intrinsic parameters :')\n",
        "    printNumpyWithIndent(cam_int, '    ')\n",
        "    print('  Distortion parameters :')\n",
        "    printNumpyWithIndent(cam_dist, '    ')\n",
        "    cam_rotation_matrix = np.zeros(shape=(3, 3))\n",
        "    cv2.Rodrigues(cam_rvecs[0], cam_rotation_matrix) \n",
        "    print('  cam_rvecs_capture_00 :')\n",
        "    printNumpyWithIndent(cam_rotation_matrix, '    ')\n",
        "    print('  cam_tvecs_capture_00 :')\n",
        "    printNumpyWithIndent(cam_tvecs[0], '    ')\n",
        "    print()\n",
        "\n",
        "    print('Initial solution of projector\\'s parameters')\n",
        "    \n",
        "    # calibrate projector by using projector corner point list and projector object point list. \n",
        "    ret, proj_int, proj_dist, proj_rvecs, proj_tvecs = cv2.calibrateCamera(\n",
        "        proj_objps_list, proj_corners_list, proj_shape, None, None, None, None)\n",
        "    \n",
        "    print('  RMS :', ret)\n",
        "    print('  Intrinsic parameters :')\n",
        "    printNumpyWithIndent(proj_int, '    ')\n",
        "    print('  Distortion parameters :')\n",
        "    printNumpyWithIndent(proj_dist, '    ')\n",
        "    proj_rotation_matrix = np.zeros(shape=(3, 3))\n",
        "    cv2.Rodrigues(proj_rvecs[0], proj_rotation_matrix) \n",
        "    print('  proj_rvecs_capture_00 :')\n",
        "    printNumpyWithIndent(proj_rotation_matrix, '    ')\n",
        "    print('  proj_tvecs_capture_00 :')\n",
        "    printNumpyWithIndent(proj_tvecs[0], '    ') \n",
        "    print()\n",
        "\n",
        "    print('=== Result ===')\n",
        "    ret, cam_int, cam_dist, proj_int, proj_dist, cam_proj_rmat, cam_proj_tvec, E, F = cv2.stereoCalibrate(\n",
        "        proj_objps_list, cam_corners_list2, proj_corners_list, cam_int, cam_dist, proj_int, proj_dist, None)\n",
        "    print('  RMS :', ret)\n",
        "    print('  Camera intrinsic parameters :')\n",
        "    printNumpyWithIndent(cam_int, '    ')\n",
        "    print('  Camera distortion parameters :')\n",
        "    printNumpyWithIndent(cam_dist, '    ')\n",
        "    print('  Projector intrinsic parameters :')\n",
        "    printNumpyWithIndent(proj_int, '    ')\n",
        "    print('  Projector distortion parameters :')\n",
        "    printNumpyWithIndent(proj_dist, '    ')\n",
        "    print('  Rotation matrix / translation vector from camera to projector')\n",
        "    print('  (they translate points from camera coord to projector coord) :')\n",
        "    printNumpyWithIndent(cam_proj_rmat, '    ')\n",
        "    printNumpyWithIndent(cam_proj_tvec, '    ')\n",
        "    print()\n",
        "\n",
        "    fovx, fovy, focalLength, principalPoint, aspectRatio = cv2.calibrationMatrixValues(proj_int, (3840, 2160), 16.4, 10.2)\n",
        "    print(\"fovx : \", fovx)\n",
        "    print(\"fovy : \", fovy)\n",
        "    print(\"focalLength : \", focalLength)\n",
        "    print(\"principalPoint : \", principalPoint)\n",
        "    print(\"aspectRatio : \", aspectRatio)\n",
        "\n",
        "    fs = cv2.FileStorage('calibration_result.xml', cv2.FILE_STORAGE_WRITE)\n",
        "    fs.write('img_shape', cam_shape)\n",
        "    fs.write('rms', ret)\n",
        "    fs.write('cam_int', cam_int)\n",
        "    fs.write('cam_dist', cam_dist)\n",
        "    fs.write('proj_int', proj_int)\n",
        "    fs.write('proj_dist', proj_dist)\n",
        "    fs.write('roration', cam_proj_rmat)\n",
        "    fs.write('translation', cam_proj_tvec)\n",
        "    fs.release()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLhNgQG0ideC"
      },
      "source": [
        "path = Path('/content/gdrive/My Drive/danbi-project/data/201110_te/1')\n",
        "#%cd /content/gdrive/My\\ Drive/procam-calibration/sample_data\n",
        "# !pwd # show me the current working directory"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_kSQr0aieww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49debf4-5bd2-4ea5-dd10-b13f26795735"
      },
      "source": [
        "cd /content/gdrive/My Drive/danbi-project/data/201110_te/1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/danbi-project/data/201110_te/1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "471QrK9Nz3Je",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65ef26a-71f5-44ae-c16f-ff5eb5b2c36c"
      },
      "source": [
        "ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m-\u001b[0m/                      \u001b[01;34mcapture_01\u001b[0m/  \u001b[01;34mcapture_04\u001b[0m/  \u001b[01;34mcapture_07\u001b[0m/  \u001b[01;34mcapture_11\u001b[0m/\n",
            "calibration_result.xml  \u001b[01;34mcapture_02\u001b[0m/  \u001b[01;34mcapture_05\u001b[0m/  \u001b[01;34mcapture_08\u001b[0m/  \u001b[01;34mcapture_12\u001b[0m/\n",
            "\u001b[01;34mcapture_00\u001b[0m/             \u001b[01;34mcapture_03\u001b[0m/  \u001b[01;34mcapture_06\u001b[0m/  \u001b[01;34mcapture_09\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWLr0_7h0aLr"
      },
      "source": [
        "proj_height = 2160 \n",
        "proj_width = 3840 \n",
        "chess_rows = 10 \n",
        "chess_cols = 7  \n",
        "chess_block_size = 96 \n",
        "graycode_step = 1\n",
        "black_thr = 40\n",
        "white_thr = 5\n",
        "camera =  \"\"\n",
        "\n",
        "main(proj_height, proj_width, chess_rows, chess_cols, chess_block_size,\n",
        "    graycode_step, black_thr, white_thr,  camera)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}