{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "procam-calibration_200828.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rim-yu/procam-calibration/blob/master/procam_calibration_200828.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70qKsQCgiIHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "273c56c9-6e97-4a05-d2d6-2b18c3ae09da"
      },
      "source": [
        "# You need to mount your google drive  to the /content/gdrive folder of your virtual computer\n",
        "# located in the colab server\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "#drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "635aMJnsiLQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "83bc04b7-37bd-43c7-ca0d-81f383c76de9"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "%xmode Verbose\n",
        "%pdb on"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception reporting mode: Verbose\n",
            "Automatic pdb calling has been turned ON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sueX8qH_iMcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "#cf: https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/\n",
        "import glob\n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "from matplotlib import pyplot as plt "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oziZ11CniOHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(proj_height, proj_width, chess_rows, chess_cols, chess_block_size,\n",
        "    graycode_step, black_thr, white_thr,  camera):\n",
        "  \n",
        "# 2160 - 3840 - 10 - 7 - 68 - 1 - 40 - 5 - \"\"\n",
        "\n",
        "    proj_shape = (proj_height, proj_width) # (2160, 3840)\n",
        "    chess_shape = (chess_rows, chess_cols) # (10, 7)\n",
        "    chess_block_size = chess_block_size # chess_block_size = 68 mm\n",
        "    gc_step = graycode_step # gc_step = 1\n",
        "    black_thr = black_thr # 40\n",
        "    white_thr = white_thr # 5\n",
        "    camera_param_file = camera # \"\"\n",
        "\n",
        "    dirnames = sorted(glob.glob('./capture_*'))\n",
        "    if len(dirnames) == 0: # capture_* 형식으로 된 폴더가 없을 경우 error 뱉음. \n",
        "        print('Directories \\'./capture_*\\' were not found')\n",
        "        return\n",
        "\n",
        "    print('Searching input files ...') # capture_* 형식으로 된 폴더가 있을 경우 파일들을 찾음. \n",
        "    used_dirnames = [] \n",
        "    gc_fname_lists = [] # 파일 이름 리스트. \n",
        "    for dname in dirnames: # capture_* 폴더 돌림. * = 1->4\n",
        "        #gc_fnames = sorted(glob.glob(dname + '/graycode_*')) # graycode_* 파일들 가져옴. \n",
        "        gc_fnames = sorted(glob.glob(dname + '/graycode*'))\n",
        "        if len(gc_fnames) == 0:  \n",
        "            continue\n",
        "        used_dirnames.append(dname) # capture_* 폴더가 순차적으로 붙음. \n",
        "        gc_fname_lists.append(gc_fnames) # 파일 이름 리스트. graycode_*가 붙음. * = 00->49\n",
        "        print(' \\'' + dname + '\\' was found') # 폴더 찾았당. \n",
        "\n",
        "    camP = None # ?\n",
        "    cam_dist = None # ? \n",
        "    path, ext = os.path.splitext(camera_param_file) # camera_param_file = \"\", 파일 이름을 확장자로부터 쪼개줌. \n",
        "    if(ext == \".json\"): # 확장자명. \n",
        "        camP, cam_dist = loadCameraParam(camera_param_file) # 카메라 파라미터 저장된 json 파일 가져옴. \n",
        "        print('load camera parameters')\n",
        "        print(camP)\n",
        "        print(cam_dist)\n",
        "\n",
        "    calibrate(used_dirnames, gc_fname_lists,\n",
        "              proj_shape, chess_shape, chess_block_size, gc_step, black_thr, white_thr,\n",
        "               camP, cam_dist) \n",
        "    # calibrate 함수 쓰는데, capture_* 폴더명들, graycode_* 파일명들, 그외 각종 변수들 + camP, cam_dist "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stpgd8rmiWM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printNumpyWithIndent(tar, indentchar):\n",
        "    print(indentchar + str(tar).replace('\\n', '\\n' + indentchar))  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59yTKzzTiYKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadCameraParam(json_file):\n",
        "    with open(json_file, 'r') as f:\n",
        "        param_data = json.load(f)\n",
        "        P = param_data['camera']['P']\n",
        "        d = param_data['camera']['distortion']\n",
        "        return np.array(P).reshape([3,3]), np.array(d) # ok "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybb9u2NciZah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calibrate(dirnames, gc_fname_lists, proj_shape, chess_shape, chess_block_size, gc_step, black_thr, white_thr, camP, camD):\n",
        "# proj_shape = (2160, 3840) chess_shape = (10, 7)    \n",
        "\n",
        "    # (1) object points\n",
        "    objps = np.zeros((chess_shape[0]*chess_shape[1], 3), np.float32) \n",
        "    # object points. 70행 3열 2차원 배열이 나타남. \n",
        "    objps[:, :2] = chess_block_size * \\\n",
        "        np.mgrid[0:chess_shape[0], 0:chess_shape[1]].T.reshape(-1, 2)\n",
        "        # [[0,0], ..., [9,0], ..., [9,9]] 이렇게 바뀜. \n",
        "        # 모든 행 2열 전까지. 즉 열 2개만. 3열은 0만.\n",
        "        # ok\n",
        "\n",
        "    # (2) projector size -> gray code \n",
        "    print('Calibrating ...') # 계산중임다. \n",
        "    gc_height = int((proj_shape[0]-1)/gc_step)+1 # 2160. \n",
        "    gc_width = int((proj_shape[1]-1)/gc_step)+1 # 3840. \n",
        "\n",
        "##### 이 부분이 \n",
        "    graycode = cv2.structured_light_GrayCodePattern.create(\n",
        "        gc_width, gc_height) # 3840 * 2160 -> 이거로 50장 만들어내는 듯.\n",
        "    graycode.setBlackThreshold(black_thr)  \n",
        "    graycode.setWhiteThreshold(white_thr) \n",
        "##### 이해가 잘 안가요.  \n",
        "\n",
        "    # (3) graycode_* size, patch_size \n",
        "    cam_shape = cv2.imread(gc_fname_lists[0][0], cv2.IMREAD_GRAYSCALE).shape \n",
        "    # cam_shape = cv2.imread(gc_fname_lists[0][0]).shape\n",
        "    # 이미지 읽기. gc_fname_lists[0][0] = graycode_00\n",
        "    # gc_fname_list 보니 맨 첫 원소는 [capture_0, graycode_00]임. \n",
        "    # cam_shape = 1600*2400 \n",
        "    patch_size_half = int(np.ceil(cam_shape[1] / 180)) # np.ceil 하면 그 값들이 '올림'된다. cam_shape = (1600, 2400)임. 왜 이건지 모르겠다. 14\n",
        "    # patch_size_half = int(np.ceil(cam_shape[1] / 270)) # 이렇게 하면 RMS가 5로 떨어지긴 하는데 카메라 내부 파라미터는 완전히 달라서 의미가 없을 듯.   \n",
        "    print('  patch size :', patch_size_half * 2 + 1) # 29\n",
        "\n",
        "    cam_corners_list = [] # 카메라 코너들을 모을 예정. \n",
        "    cam_objps_list = [] # 카메라 object들을 모을 예정. \n",
        "    cam_corners_list2 = [] # 보류\n",
        "    _cam_corners_list = [] \n",
        "\n",
        "    proj_corners_list = [] # 프로젝터 코너들을 모을 예정\n",
        "    proj_objps_list = [] # 프로젝터 object들을 모을 예정 \n",
        "    \n",
        "    # (4) dirnames = capture_*, gc_fname_lists = graycode_*\n",
        "    for dname, gc_filenames in zip(dirnames, gc_fname_lists): # 폴더-파일  \n",
        "        print('  checking \\'' + dname + '\\'') # dirname = capture_*\n",
        "        if len(gc_filenames) != graycode.getNumberOfPatternImages() + 2:\n",
        "            print('Error : invalid number of images in \\'' + dname + '\\'')\n",
        "            return None \n",
        "            # graycode.getNumberOfPatternImages() = 48. 2를 더해서 50이 아닐 경우 에러내라. \n",
        "\n",
        "        imgs = []\n",
        "        _imgpoints = []\n",
        "\n",
        "        for fname in gc_filenames: # 각 graycode_*\n",
        "            img = cv2.imread(fname)\n",
        "            # img = cv2.imread(fname, cv2.IMREAD_GRAYSCALE) # graycode_*를 흑백 모드에서 이미지 로드. 채널 하나구나.       \n",
        "            # 앞에 _를 붙힌 변수는 image point들을 camera calibration과 동일하게 설정하려 임의로 추가한 코드임다. \n",
        "            # _gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            _gray = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if cam_shape != _gray.shape: # (원래) img.shape: # cam_shape = (1600, 2400, 3)\n",
        "                print('Error : image size of \\'' + fname + '\\' is mismatch')\n",
        "                return None # 흑백 모드에서 로드한 이미지가 (1600, 2400)의 사이즈를 갖지 않으면 에러내라.\n",
        "                # gray scale로 하면 shape이 바뀜.  \n",
        "\n",
        "            #imgs.append(img) # 빈 리스트에 img(graycode_*)를 연쇄적으로 추가함.  \n",
        "            imgs.append(_gray)\n",
        "\n",
        "        black_img = imgs.pop() #imgs.pop() # graycode_49를 black_img로 지정함. 대다수의 0을 가진 매트릭스. graycode_49는 프로젝터에서 검정색 화면만 쏜 것임. \n",
        "        white_img = imgs.pop() #imgs.pop() # graycode_48을 white_img로 지정함. 37~60을 가진 매트릭스. graycode_48은 프로젝터에서 하얀색 화면만 쏜 것임.\n",
        "        # pop() 2회를 통해 imgs에는 48장의 이미지만이 남음.  \n",
        "        # cv2_imshow(white_img)를 통해 black_img와 white_img를 확인할 수 있다. \n",
        "\n",
        "        # 원래 코드 \n",
        "        res, cam_corners = cv2.findChessboardCorners(white_img, chess_shape) # white_img를 통해 체스보드판의 코너들을 찾아낸다. \n",
        "        \n",
        "        if not res: # res는 코너점들을 찾았는지 알려줌. \n",
        "            print('Error : chessboard was not found in \\'' +\n",
        "                  gc_filenames[-2] + '\\'')  \n",
        "            return None\n",
        "\n",
        "        # 수정한 코드 \n",
        "        # _ret, _corners = cv2.findChessboardCorners(_gray, (10, 7), None)\n",
        "        _ret, _corners = cv2.findChessboardCorners(white_img, (10, 7), None)\n",
        "\n",
        "        if _ret == True:\n",
        "            _corners2 = cv2.cornerSubPix(white_img, _corners, (11, 11), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
        "            _imgpoints.append(_corners2)\n",
        "\n",
        "        #_ChessboardCorners = cv2.drawChessboardCorners(img, (10, 7), _corners2, _ret) \n",
        "        #if dname == \"./capture_00\" :\n",
        "        #    plt.figure(figsize=(30, 30))\n",
        "        #    plt.imshow(_ChessboardCorners)\n",
        "        #    plt.axis(\"off\")\n",
        "        #    plt.show()\n",
        "\n",
        "        cam_objps_list.append(objps) # 카메라 object들을 모아놓음. \n",
        "        cam_corners_list.append(cam_corners) # 카메라 코너들을 모아놓음. \n",
        "        _cam_corners_list.append(_corners2) \n",
        "\n",
        "        # procam calibration을 본격화하려는 모양. \n",
        "        # 위에서 정의한 proj_corners_list = [], proj_objps_list = [] 이 두 변수와 아래 변수들이 뭐가 다른지 생각 좀 해야할 듯. \n",
        "        proj_objps = []\n",
        "        proj_corners = []\n",
        "        cam_corners2 = []\n",
        "\n",
        "        # viz_proj_points = np.zeros(proj_shape, np.uint8)\n",
        "        for corner, objp in zip(cam_corners, objps): # 코너들 - object들   \n",
        "            c_x = int(round(corner[0][0])) # round 함수는 반올림. c_x는 코너(1).\n",
        "            c_y = int(round(corner[0][1])) # c_y는 코너(2).\n",
        "            src_points = []\n",
        "            dst_points = []\n",
        "            for dx in range(-patch_size_half, patch_size_half + 1): # -14~15. 29만큼, path_size만큼 for문이 돌아감. \n",
        "                for dy in range(-patch_size_half, patch_size_half + 1):\n",
        "                    x = c_x + dx \n",
        "                    y = c_y + dy\n",
        "                    # 최소 196개의 (x,y) 좌표를 가져와야 ok. \n",
        "\n",
        "                    # white_img[y, x]는 (y, x) 지점의 픽셀값을 보여줌. \n",
        "                    if int(white_img[y, x]) - int(black_img[y, x]) <= black_thr: # white_img, black_img의 (x, y) 지점에서 차이를 구할 때 그 픽셀값이 black_thr = 40보다 작으면 okay. \n",
        "                        continue # 그 차이가 40보다 작아야지 (x, y) 좌표를 가져올 수 있는 건데 capture_1의 경우 그 차이가 40보다 큰 것임. \n",
        "\n",
        "                    err, proj_pix = graycode.getProjPixel(imgs, x, y) # projector 관련.\n",
        "\n",
        "                    if not err:\n",
        "                        src_points.append((x, y)) # src_points에 (x, y) 값들이 기록되는 것임.   \n",
        "                        dst_points.append(gc_step*np.array(proj_pix)) # 보류. \n",
        "            if len(src_points) < patch_size_half**2: # path_size_half**2 = 196. (x, y)가 모여서 196개는 나와야 하는데 (x, y)가 덜 모이면 에러가 발생하는 것임.  \n",
        "                print(\n",
        "                    '    Warning : corner', c_x, c_y,\n",
        "                    'was skiped because decoded pixels were too few (check your images and threasholds)') # 디코드된 값이 너무 적다고.\n",
        "                continue\n",
        "            h_mat, inliers = cv2.findHomography(\n",
        "                np.array(src_points), np.array(dst_points))\n",
        "            point = h_mat@np.array([corner[0][0], corner[0][1], 1]).transpose()\n",
        "            point_pix = point[0:2]/point[2]\n",
        "            proj_objps.append(objp)\n",
        "            proj_corners.append([point_pix])\n",
        "            cam_corners2.append(corner)\n",
        "            # viz_proj_points[int(round(point_pix[1])),\n",
        "            #                 int(round(point_pix[0]))] = 255\n",
        "\n",
        "        if len(proj_corners) < 3:\n",
        "            print('Error : too few corners were found in \\'' +\n",
        "                  dname + '\\' (less than 3)')\n",
        "            return None\n",
        "        proj_objps_list.append(np.float32(proj_objps))\n",
        "        proj_corners_list.append(np.float32(proj_corners))\n",
        "        cam_corners_list2.append(np.float32(cam_corners2))\n",
        "        # cv2.imwrite('visualize_corners_projector_' +\n",
        "        #             str(cnt) + '.png', viz_proj_points)\n",
        "        # cnt += 1\n",
        "\n",
        "    print('Initial solution of camera\\'s intrinsic parameters')\n",
        "    cam_rvecs = []\n",
        "    cam_tvecs = []\n",
        "    if(camP is None):\n",
        "        ret, cam_int, cam_dist, cam_rvecs, cam_tvecs = cv2.calibrateCamera(\n",
        "            cam_objps_list, _cam_corners_list, _gray.shape[::-1], None, None, None, None) # cam_shape -> _gray.shape[::-1]\n",
        "        print('  RMS :', ret)\n",
        "    else:\n",
        "        for objp, corners in zip(cam_objps_list, _cam_corners_list):##\n",
        "            ret, cam_rvec, cam_tvec = cv2.solvePnP(objp, corners, camP, camD) # 외부 파라미터 구하는 함수.  \n",
        "            cam_rvecs.append(cam_rvec)\n",
        "            cam_tvecs.append(cam_tvec)\n",
        "            print('  RMS :', ret)\n",
        "        cam_int = camP\n",
        "        cam_dist = camD\n",
        "    print('  Intrinsic parameters :')\n",
        "    printNumpyWithIndent(cam_int, '    ')\n",
        "    print('  Distortion parameters :')\n",
        "    printNumpyWithIndent(cam_dist, '    ')\n",
        "    cam_rotation_matrix = np.zeros(shape=(3, 3))\n",
        "    cv2.Rodrigues(cam_rvecs[0], cam_rotation_matrix) \n",
        "    # Rodrigues로 표현된(3*1) R vectors를 3*3으로 표현하기 위함.\n",
        "    # 체스보드를 바닥에 딱 붙힌 capture_00에 대해서 rotation vector를 구하겠음.  \n",
        "    print('  cam_rvecs_capture_00 :')\n",
        "    printNumpyWithIndent(cam_rotation_matrix, '    ')\n",
        "    print('  cam_tvecs_capture_00 :')\n",
        "    printNumpyWithIndent(cam_tvecs[0], '    ')\n",
        "    print()\n",
        "\n",
        "    print('Initial solution of projector\\'s parameters')\n",
        "    ret, proj_int, proj_dist, proj_rvecs, proj_tvecs = cv2.calibrateCamera(\n",
        "        proj_objps_list, proj_corners_list, proj_shape, None, None, None, None)\n",
        "    \n",
        "    print('  RMS :', ret)\n",
        "    print('  Intrinsic parameters :')\n",
        "    printNumpyWithIndent(proj_int, '    ')\n",
        "    print('  Distortion parameters :')\n",
        "    printNumpyWithIndent(proj_dist, '    ')\n",
        "    proj_rotation_matrix = np.zeros(shape=(3, 3))\n",
        "    cv2.Rodrigues(proj_rvecs[0], proj_rotation_matrix) # Rodrigues로 표현된(3*1) R vectors를 3*3으로 표현하기 위함. \n",
        "    print('  proj_rvecs_capture_00 :')\n",
        "    printNumpyWithIndent(proj_rotation_matrix, '    ')\n",
        "    print('  proj_tvecs_capture_00 :')\n",
        "    printNumpyWithIndent(proj_tvecs[0], '    ') \n",
        "    print()\n",
        "\n",
        "    print('=== Result ===')\n",
        "    ret, cam_int, cam_dist, proj_int, proj_dist, cam_proj_rmat, cam_proj_tvec, E, F = cv2.stereoCalibrate(\n",
        "        proj_objps_list, cam_corners_list2, proj_corners_list, cam_int, cam_dist, proj_int, proj_dist, None)\n",
        "    print('  RMS :', ret)\n",
        "    print('  Camera intrinsic parameters :')\n",
        "    printNumpyWithIndent(cam_int, '    ')\n",
        "    print('  Camera distortion parameters :')\n",
        "    printNumpyWithIndent(cam_dist, '    ')\n",
        "    print('  Projector intrinsic parameters :')\n",
        "    printNumpyWithIndent(proj_int, '    ')\n",
        "    print('  Projector distortion parameters :')\n",
        "    printNumpyWithIndent(proj_dist, '    ')\n",
        "    print('  Rotation matrix / translation vector from camera to projector')\n",
        "    print('  (they translate points from camera coord to projector coord) :')\n",
        "    printNumpyWithIndent(cam_proj_rmat, '    ')\n",
        "    printNumpyWithIndent(cam_proj_tvec, '    ')\n",
        "    print()\n",
        "\n",
        "    fs = cv2.FileStorage('calibration_result.xml', cv2.FILE_STORAGE_WRITE)\n",
        "    fs.write('img_shape', cam_shape)\n",
        "    fs.write('rms', ret)\n",
        "    fs.write('cam_int', cam_int)\n",
        "    fs.write('cam_dist', cam_dist)\n",
        "    fs.write('proj_int', proj_int)\n",
        "    fs.write('proj_dist', proj_dist)\n",
        "    fs.write('roration', cam_proj_rmat)\n",
        "    fs.write('translation', cam_proj_tvec)\n",
        "    fs.release()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLhNgQG0ideC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Path('/content/gdrive/My Drive/danbi-project/data/200805_1')\n",
        "#%cd /content/gdrive/My\\ Drive/procam-calibration/sample_data\n",
        "# !pwd # show me the current working directory"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_kSQr0aieww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "003adfb1-1539-4e50-82a6-85c969584a97"
      },
      "source": [
        "cd /content/gdrive/\"My Drive\"/danbi-project/data/200805_1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/danbi-project/data/200805_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "471QrK9Nz3Je",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "5f2f4781-f9dd-4112-a4c2-601d7a7e05e8"
      },
      "source": [
        "ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m-\u001b[0m/                      \u001b[01;34mcapture_01\u001b[0m/  \u001b[01;34mcapture_04\u001b[0m/  \u001b[01;34mcapture_08\u001b[0m/  \u001b[01;34mcapture_12\u001b[0m/\n",
            "calibration_result.xml  \u001b[01;34mcapture_02\u001b[0m/  \u001b[01;34mcapture_06\u001b[0m/  \u001b[01;34mcapture_10\u001b[0m/  \u001b[01;34mcapture_14\u001b[0m/\n",
            "\u001b[01;34mcapture_00\u001b[0m/             \u001b[01;34mcapture_03\u001b[0m/  \u001b[01;34mcapture_07\u001b[0m/  \u001b[01;34mcapture_11\u001b[0m/  \u001b[01;34mcapture_15\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w97ZhDQTJPYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71b7f9ba-7e4e-4f9d-d237-0a2b76dfbcd4"
      },
      "source": [
        "proj_height = 2160 \n",
        "proj_width = 3840\n",
        "chess_rows = 10 \n",
        "chess_cols = 7  \n",
        "chess_block_size = 96\n",
        "graycode_step = 1\n",
        "black_thr = 40\n",
        "white_thr = 2\n",
        "camera =  \"\"\n",
        "\n",
        "main(proj_height, proj_width, chess_rows, chess_cols, chess_block_size,\n",
        "    graycode_step, black_thr, white_thr,  camera)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching input files ...\n",
            " './capture_00' was found\n",
            " './capture_01' was found\n",
            " './capture_02' was found\n",
            " './capture_03' was found\n",
            " './capture_04' was found\n",
            " './capture_06' was found\n",
            " './capture_07' was found\n",
            " './capture_08' was found\n",
            " './capture_10' was found\n",
            " './capture_11' was found\n",
            " './capture_12' was found\n",
            " './capture_14' was found\n",
            " './capture_15' was found\n",
            "Calibrating ...\n",
            "  patch size : 29\n",
            "  checking './capture_00'\n",
            "  checking './capture_01'\n",
            "  checking './capture_02'\n",
            "  checking './capture_03'\n",
            "  checking './capture_04'\n",
            "  checking './capture_06'\n",
            "  checking './capture_07'\n",
            "  checking './capture_08'\n",
            "  checking './capture_10'\n",
            "  checking './capture_11'\n",
            "  checking './capture_12'\n",
            "  checking './capture_14'\n",
            "  checking './capture_15'\n",
            "Initial solution of camera's intrinsic parameters\n",
            "  RMS : 0.7241568277087241\n",
            "  Intrinsic parameters :\n",
            "    [[2.02303721e+03 0.00000000e+00 1.20980420e+03]\n",
            "     [0.00000000e+00 2.02418275e+03 8.21426626e+02]\n",
            "     [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
            "  Distortion parameters :\n",
            "    [[-1.89685625e-01  4.32916878e-01  3.70648120e-05  6.83094571e-04\n",
            "      -8.80839990e-01]]\n",
            "  cam_rvecs_capture_00 :\n",
            "    [[-0.99601225 -0.08855388  0.01085398]\n",
            "     [ 0.08866735 -0.99600637  0.01046007]\n",
            "     [ 0.00988435  0.01138075  0.99988638]]\n",
            "  cam_tvecs_capture_00 :\n",
            "    [[ 276.39040931]\n",
            "     [ 204.66910348]\n",
            "     [1732.75087476]]\n",
            "\n",
            "Initial solution of projector's parameters\n",
            "  RMS : 0.9804553349525968\n",
            "  Intrinsic parameters :\n",
            "    [[3.24314197e+03 0.00000000e+00 1.92255034e+03]\n",
            "     [0.00000000e+00 3.24133382e+03 1.08935447e+03]\n",
            "     [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
            "  Distortion parameters :\n",
            "    [[-0.00890309  0.21468393 -0.00096848 -0.00285795 -0.54559383]]\n",
            "  proj_rvecs_capture_00 :\n",
            "    [[-9.99984325e-01 -5.59901665e-03  5.84897872e-06]\n",
            "     [ 5.59862145e-03 -9.99925110e-01 -1.08825467e-02]\n",
            "     [ 6.67801009e-05 -1.08823434e-02  9.99940783e-01]]\n",
            "  proj_tvecs_capture_00 :\n",
            "    [[ 611.82781084]\n",
            "     [ 407.56942583]\n",
            "     [2119.22585348]]\n",
            "\n",
            "=== Result ===\n",
            "  RMS : 0.9592677989771806\n",
            "  Camera intrinsic parameters :\n",
            "    [[2.02303721e+03 0.00000000e+00 1.20980420e+03]\n",
            "     [0.00000000e+00 2.02418275e+03 8.21426626e+02]\n",
            "     [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
            "  Camera distortion parameters :\n",
            "    [[-1.89685625e-01  4.32916878e-01  3.70648120e-05  6.83094571e-04\n",
            "      -8.80839990e-01]]\n",
            "  Projector intrinsic parameters :\n",
            "    [[3.24314197e+03 0.00000000e+00 1.92255034e+03]\n",
            "     [0.00000000e+00 3.24133382e+03 1.08935447e+03]\n",
            "     [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
            "  Projector distortion parameters :\n",
            "    [[-0.00890309  0.21468393 -0.00096848 -0.00285795 -0.54559383]]\n",
            "  Rotation matrix / translation vector from camera to projector\n",
            "  (they translate points from camera coord to projector coord) :\n",
            "    [[ 0.99663129 -0.08155148 -0.00868462]\n",
            "     [ 0.08135873  0.99647157 -0.0206198 ]\n",
            "     [ 0.01033555  0.01984377  0.99974967]]\n",
            "    [[368.10657134]\n",
            "     [216.21286606]\n",
            "     [377.9167948 ]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3s11ZdGcldh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####\n",
        "import numpy as np\n",
        "\n",
        "tvec_wc = np.array([276.39040931, 204.66910348, 1732.75087476])\n",
        "rvec_wc = np.array([[-0.99601225, -0.08855388, 0.01085398],\n",
        "                   [0.08866735, -0.99600637, 0.01046007],\n",
        "                   [0.00988435, 0.01138075, 0.99988638]])\n",
        "print(\"tvec_wc : \\n\", tvec_wc)\n",
        "print(\"rvec_wc : \\n\", rvec_wc)\n",
        "# Pc = R*Pw + T\n",
        "# Pw = R.T*Pc - R.T*T\n",
        "\n",
        "tvec_cw = -np.matmul(rvec_wc.T, tvec_wc)\n",
        "rvec_cw = rvec_wc.T\n",
        "print(\"tvec_cw : \\n\", tvec_cw)\n",
        "print(\"rvec_cw : \\n\", rvec_cw)\n",
        "\n",
        "tvec_cp = np.array([368.10657134l, 216.21286606, 377.9167948])\n",
        "rvec_cp = np.array([[0.99663129, -0.08155148, -0.00868462],\n",
        "                   [0.08135873, 0.99647157, -0.0206198],\n",
        "                   [0.01033555, 0.01984377, 0.99974967]])\n",
        "print(\"tvec_cp : \\n\", tvec_cp)\n",
        "print(\"rvec_cp : \\n\", rvec_cp)\n",
        "\n",
        "tvec_pc = -np.matmul(rvec_cp.T, tvec_cp)\n",
        "rvec_pc = rvec_cp.T\n",
        "print(\"tvec_pc : \\n\", tvec_pc)\n",
        "print(\"rvec_pc : \\n\", rvec_pc)\n",
        "\n",
        "tvec_wp = np.array([611.82781084, 407.56942583, 2119.22585348])\n",
        "rvec_wp = np.array([[-9.99984325e-01, -5.59901665e-03, 5.84897872e-06],\n",
        "                   [5.59862145e-03, -9.99925110e-01, -1.08825467e-02],\n",
        "                   [6.67801009e-05 -1.08823434e-02  9.99940783e-01]]\n",
        "print(\"tvec_wp : \\n\", tvec_wp)\n",
        "print(\"rvec_wp : \\n\", rvec_wp)\n",
        "\n",
        "tvec_pw = -np.matmul(rvec_wp.T, tvec_wp)\n",
        "rvec_pw = rvec_wp.T\n",
        "print(\"tvec_pw : \\n\", tvec_pw)\n",
        "print(\"rvec_pw : \\n\", rvec_pw)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}